{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Word2Vec 을 이용한 평점 및 메타데이터 기반 영화 추천기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 여러가지 영화 데이터를 로드합니다. <br>\n",
    "영화 데이터는 MovieLens의 데이터를 사용하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from operator import itemgetter\n",
    "import random\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "tag = pd.read_csv('./data/tags_small.csv')\n",
    "movie = pd.read_csv('./data/movies_small.csv')\n",
    "# 각종 데이터를 로드합니다.\n",
    "\n",
    "tag_df = pd.DataFrame(tag)\n",
    "movie_df = pd.DataFrame(movie)\n",
    "# 데이터 프레임을 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['will ferrell', 'funny', 'highly quotable']\n['mma', 'tom hardy', 'boxing story']\n['leonardo dicaprio', 'drugs', 'martin scorsese']\n['gangster', 'mafia']\n['mafia', 'al pacino']\n['holocaust', 'true story']\n['twist ending']\n['twist ending', 'anthony hopkins', 'courtroom drama']\n['britpop', 'indie record label', 'music']\n['dumpster diving', 'sustainability']\n"
     ]
    }
   ],
   "source": [
    "my_array = []\n",
    "tmp_array = []\n",
    "tmp_for_movie_id = 60756\n",
    "tmp_for_user_id = 2\n",
    "from operator import itemgetter\n",
    "\n",
    "for userId, movieId, tag, time in tag_df.values:\n",
    "\n",
    "    global lower_tag\n",
    "    if tmp_for_user_id == userId:\n",
    "        if tmp_for_movie_id == movieId:\n",
    "            lower_tag = tag.lower()\n",
    "            data_dict = {'time': time, 'tag': lower_tag}\n",
    "            tmp_array.append(data_dict)\n",
    "\n",
    "        else:\n",
    "            sorted_list = sorted(tmp_array, key=itemgetter('time'))\n",
    "            sorted_tag_list = []\n",
    "            for i in sorted_list:\n",
    "                sorted_tag_list.append(i.get('tag'))\n",
    "            my_array.append(list(sorted_tag_list))\n",
    "            tmp_for_movie_id = movieId\n",
    "            tmp_array.clear()\n",
    "            if not(type(tag) is float):\n",
    "                lower_tag = tag.lower()\n",
    "            tmp_array.append({'time': time, 'tag': lower_tag})\n",
    "\n",
    "    else:\n",
    "        tmp_for_user_id = userId\n",
    "\n",
    "for i in range(0, 10):\n",
    "    print(my_array[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = []\n",
    "s_array = []\n",
    "\n",
    "for separate_array in my_array:\n",
    "    arr = list(separate_array)\n",
    "    s_array.append(arr)\n",
    "    for word in separate_array:\n",
    "        words.append(word)\n",
    "\n",
    "word2int = {}\n",
    "int2word = {}\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    word2int[word] = i\n",
    "    int2word[i] = word\n",
    "\n",
    "sentences = []\n",
    "for sentence in s_array:\n",
    "    sentences.append(sentence)\n",
    "\n",
    "WINDOW_SIZE = 3\n",
    "\n",
    "data = []\n",
    "for sentence in sentences:\n",
    "    for idx, word in enumerate(sentence):\n",
    "        for neighbor in sentence[max(idx - WINDOW_SIZE, 0): min(idx + WINDOW_SIZE, len(sentence)) + 1]:\n",
    "            if neighbor != word:\n",
    "                data.append([word, neighbor])\n",
    "\n",
    "df = pd.DataFrame(data, columns=['input', 'label'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 0 현재 코스트 :  7.025462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 10 현재 코스트 :  6.4800644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 20 현재 코스트 :  5.9871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 30 현재 코스트 :  4.9634094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 40 현재 코스트 :  3.4899917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 50 현재 코스트 :  2.766042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 60 현재 코스트 :  2.5412464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 70 현재 코스트 :  2.467911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 80 현재 코스트 :  2.4385133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 90 현재 코스트 :  2.4247668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 100 현재 코스트 :  2.4177186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 110 현재 코스트 :  2.413616\n"
     ]
    }
   ],
   "source": [
    "ONE_HOT_DIM = len(words)\n",
    "\n",
    "\n",
    "# 큰숫자 (예를들어 35, 43 등)를 원핫 인코딩 시키는 함수.\n",
    "# 35 -> (0,0,0,0,.....,1,0,0,0)\n",
    "# 36 -> (0,0,0,0,.....,0,1,0,0)\n",
    "def to_one_hot_encoding(data_point_index):\n",
    "    one_hot_encoding = np.zeros(ONE_HOT_DIM)\n",
    "    one_hot_encoding[data_point_index] = 1\n",
    "    return one_hot_encoding\n",
    "\n",
    "\n",
    "X = []  # 입력 배열입니다.\n",
    "Y = []  # 타겟단어입니다.\n",
    "\n",
    "for x, y in zip(df['input'], df['label']):\n",
    "    X.append(to_one_hot_encoding(word2int[x]))\n",
    "    Y.append(to_one_hot_encoding(word2int[y]))\n",
    "\n",
    "# 넘파이 어레이로 변경\n",
    "X_train = np.asarray(X)\n",
    "Y_train = np.asarray(Y)\n",
    "\n",
    "# 학습과정을 위한 placeholder 생성\n",
    "x = tf.placeholder(tf.float32, shape=(None, ONE_HOT_DIM))\n",
    "y_label = tf.placeholder(tf.float32, shape=(None, ONE_HOT_DIM))\n",
    "\n",
    "EMBEDDING_DIM = 256\n",
    "\n",
    "# 이 두개의 값은 각각 히든레이어의 변수가 됩니다.\n",
    "W1 = tf.get_variable(str(random.random()), shape=[ONE_HOT_DIM, EMBEDDING_DIM],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([1]))\n",
    "L1 = tf.add(tf.matmul(x, W1), b1)\n",
    "\n",
    "# 출력값\n",
    "W2 = tf.get_variable(str(random.random()), shape=[EMBEDDING_DIM, ONE_HOT_DIM],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([1]))\n",
    "prediction = tf.nn.softmax(tf.add(tf.matmul(L1, W2), b2))\n",
    "\n",
    "# 코스트합수 : 크로스 엔트로피\n",
    "loss = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(prediction), axis=[1]))\n",
    "\n",
    "# 학습과정\n",
    "train_op = tf.train.AdamOptimizer(0.01).minimize(loss)\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "iteration = 120\n",
    "\n",
    "for i in range(iteration):\n",
    "    sess.run(train_op, feed_dict={x: X_train, y_label: Y_train})\n",
    "    if i % 10 == 0:\n",
    "        print('학습 ' + str(i) + ' 현재 코스트 : ', sess.run(loss, feed_dict={x: X_train, y_label: Y_train}))\n",
    "\n",
    "vectors = sess.run(W1 + b1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def euclidean_dist(vec1, vec2):\n",
    "    return np.sqrt(np.sum((vec1 - vec2) ** 2))\n",
    "\n",
    "\n",
    "def find_close(word_index):\n",
    "    min_dist = 100\n",
    "    query_vector = vectors[word_index]\n",
    "    temp = []\n",
    "    for index, vector in enumerate(vectors):\n",
    "        if euclidean_dist(vector, query_vector) < min_dist and not np.array_equal(vector, query_vector):\n",
    "            min_dist = euclidean_dist(vector, query_vector)\n",
    "            min_index = index\n",
    "            temp.append({'dist': min_dist, 'tag': min_index})\n",
    "\n",
    "    temp.append({'dist': 0, 'tag': word_index})\n",
    "    sorted_list = sorted(temp, key=itemgetter('dist'))\n",
    "    return sorted_list\n",
    "\n",
    "\n",
    "def get_tag(word_index):\n",
    "    tag_list = []\n",
    "    for i in find_close(word_index):\n",
    "        tag_list.append(i.get('tag'))\n",
    "\n",
    "    return tag_list\n",
    "\n",
    "\n",
    "def get_distance(word_index):\n",
    "    dist_list = []\n",
    "    for i in find_close(word_index):\n",
    "        dist_list.append(i.get('dist'))\n",
    "\n",
    "    return dist_list\n",
    "\n",
    "\n",
    "num = 4\n",
    "\n",
    "\n",
    "def find_closet_tag(word):\n",
    "    idx = 0\n",
    "    indexes = get_tag(word2int[word])\n",
    "    distances = get_distance(word2int[word])\n",
    "    for i in zip(indexes, distances):\n",
    "        idx = idx+1\n",
    "        if idx < num:\n",
    "            print('태그 : ', int2word[i[0]], ' 거리 : ', i[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thor  태그와 가장 비슷한 태그의 목록입니다.\n===============================\n태그 :  thor  거리 :  0\n태그 :  guardians of the galaxy  거리 :  7.2580013\n태그 :  dr. strange  거리 :  7.5442257\n\n\nbritish gangster  태그와 가장 비슷한 태그의 목록입니다.\n===============================\n태그 :  british gangster  거리 :  0\n태그 :  exquisite plotting.  거리 :  8.033359\n태그 :  daniel craig  거리 :  8.224353\n\n\nstar wars  태그와 가장 비슷한 태그의 목록입니다.\n===============================\n태그 :  star wars  거리 :  0\n태그 :  classic sci-fi  거리 :  8.002581\n태그 :  space adventure  거리 :  8.360639\n"
     ]
    }
   ],
   "source": [
    "test = 'thor'\n",
    "print(test, ' 태그와 가장 비슷한 태그의 목록입니다.')\n",
    "print('===============================')\n",
    "\n",
    "find_closet_tag(test)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "test = 'british gangster'\n",
    "print(test, ' 태그와 가장 비슷한 태그의 목록입니다.')\n",
    "print('===============================')\n",
    "\n",
    "find_closet_tag(test)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "test = 'star wars'\n",
    "print(test, ' 태그와 가장 비슷한 태그의 목록입니다.')\n",
    "print('===============================')\n",
    "\n",
    "find_closet_tag(test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
