{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 텐서플로우를 활용한 Word2Vec 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "임의로 만든 데이터 배열을 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['예뻐 너가좋아 좋아해 사랑해',\n",
    "          '데이터마이닝 인공지능 김순태교수',\n",
    "          '데이터 4차산업혁명 데이터마이닝',\n",
    "          '인공지능 AI 빅데이터 데이터',\n",
    "          '좋아해 사랑해 행복해 너가좋아',\n",
    "          '페이커 롤 보겸 아프리카',\n",
    "          '김순태교수 전북대학교 연구실',\n",
    "          '전북대학교 인공지능 연구실',\n",
    "          '데이터 4차산업혁명 전북대학교',\n",
    "          '롤 오버워치 게임 블리자드',\n",
    "          '던전앤파이터 리니지 오버워치 롤',\n",
    "          '메이플스토리 롤 페이커 리니지 게임 오버워치',\n",
    "          '전북대학교 대학생 김순태교수 블록체인',\n",
    "          '블록체인 연구실 빅데이터',\n",
    "          '여자친구 사랑해 행복해 영원한 사랑',\n",
    "          '남자친구 좋아해 너가좋아 여자친구',\n",
    "          '남자친구 여자친구 사랑 행복'\n",
    "          '메이플스토리 리그오브레전드 롤',\n",
    "          '히오스 히어로즈오브스톰 스타크래프트 롤 리그오브레전드',\n",
    "          '블리자드 오버워치 시공조아 스타크래프트 히오스',\n",
    "          '전북대학교 학교 대학교 연구실',\n",
    "          '여자친구 사랑 행복 영원한',\n",
    "          '정우성 영화 전지현',\n",
    "          '김사랑 영화 조인성 권상우',\n",
    "          '정우성 전지현 배우 영화배우 영화 권상우',\n",
    "          '영화 배우 영화배우 권상우 감독 영화감독',\n",
    "          '영화관 심화영화 영화 영화감독',\n",
    "          '조인성 눈물연기 연기대상 영화배우',\n",
    "          '영화배우 연기대상 김사랑 전지현',\n",
    "          '게임 스타크래프트 오버워치',\n",
    "          '페이커 던전앤파이터 스타크래프트 메이플스토리 프로게이머',\n",
    "          '스타크래프트 임요환 게임 페이커 롤챔스',\n",
    "          '홍진호 폭풍저그 게임 임요환 롤챔스 페이커',\n",
    "          '게임 홍진호 폭풍저그 테란 임요환 페이커',\n",
    "          '게임 스타크래프트 오버워치 롤',\n",
    "          '서든어택 롤 게임 스타크래프트',\n",
    "          '롤 스타크래프트 홍진호 게임']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "임의로 정의한 문장배열을 단어별로 정리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "\n",
    "for text in corpus:\n",
    "    for word in text.split(' '):\n",
    "        words.append(word)\n",
    "\n",
    "words = set(words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어의 목록입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'4차산업혁명',\n 'AI',\n '감독',\n '게임',\n '권상우',\n '김사랑',\n '김순태교수',\n '남자친구',\n '너가좋아',\n '눈물연기',\n '대학교',\n '대학생',\n '던전앤파이터',\n '데이터',\n '데이터마이닝',\n '롤',\n '롤챔스',\n '리그오브레전드',\n '리니지',\n '메이플스토리',\n '배우',\n '보겸',\n '블록체인',\n '블리자드',\n '빅데이터',\n '사랑',\n '사랑해',\n '서든어택',\n '스타크래프트',\n '시공조아',\n '심화영화',\n '아프리카',\n '여자친구',\n '연구실',\n '연기대상',\n '영원한',\n '영화',\n '영화감독',\n '영화관',\n '영화배우',\n '예뻐',\n '오버워치',\n '인공지능',\n '임요환',\n '전북대학교',\n '전지현',\n '정우성',\n '조인성',\n '좋아해',\n '테란',\n '페이커',\n '폭풍저그',\n '프로게이머',\n '학교',\n '행복',\n '행복메이플스토리',\n '행복해',\n '홍진호',\n '히어로즈오브스톰',\n '히오스'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word2int set을 정의하고 각 단어들마다 1씩 올려가며 숫자를 매깁니다. <br>\n",
    "그리고 window size를 2로 설정해서 양옆의 단어와 짝을 이룬 벡터를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2int = {}\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    word2int[word] = i\n",
    "\n",
    "sentences = []\n",
    "for sentence in corpus:\n",
    "    sentences.append(sentence.split())\n",
    "\n",
    "WINDOW_SIZE = 2\n",
    "\n",
    "data = []\n",
    "for sentence in sentences:\n",
    "    for idx, word in enumerate(sentence):\n",
    "        for neighbor in sentence[max(idx - WINDOW_SIZE, 0): min(idx + WINDOW_SIZE, len(sentence)) + 1]:\n",
    "            if neighbor != word:\n",
    "                data.append([word, neighbor])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas를 import하고 데이터프레임을 2차원의 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data, columns=['input', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>예뻐</td>\n",
       "      <td>너가좋아</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>예뻐</td>\n",
       "      <td>좋아해</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>너가좋아</td>\n",
       "      <td>예뻐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>너가좋아</td>\n",
       "      <td>좋아해</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>너가좋아</td>\n",
       "      <td>사랑해</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>좋아해</td>\n",
       "      <td>예뻐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>좋아해</td>\n",
       "      <td>너가좋아</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>좋아해</td>\n",
       "      <td>사랑해</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>사랑해</td>\n",
       "      <td>너가좋아</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>사랑해</td>\n",
       "      <td>좋아해</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>데이터마이닝</td>\n",
       "      <td>인공지능</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>데이터마이닝</td>\n",
       "      <td>김순태교수</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>인공지능</td>\n",
       "      <td>데이터마이닝</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>인공지능</td>\n",
       "      <td>김순태교수</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>김순태교수</td>\n",
       "      <td>데이터마이닝</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>김순태교수</td>\n",
       "      <td>인공지능</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>데이터</td>\n",
       "      <td>4차산업혁명</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>데이터</td>\n",
       "      <td>데이터마이닝</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4차산업혁명</td>\n",
       "      <td>데이터</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4차산업혁명</td>\n",
       "      <td>데이터마이닝</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>데이터마이닝</td>\n",
       "      <td>데이터</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>데이터마이닝</td>\n",
       "      <td>4차산업혁명</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>인공지능</td>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>인공지능</td>\n",
       "      <td>빅데이터</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>AI</td>\n",
       "      <td>인공지능</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>예뻐</td>\n",
       "      <td>너가좋아</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>예뻐</td>\n",
       "      <td>좋아해</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>너가좋아</td>\n",
       "      <td>예뻐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>너가좋아</td>\n",
       "      <td>좋아해</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>너가좋아</td>\n",
       "      <td>사랑해</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>좋아해</td>\n",
       "      <td>예뻐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>좋아해</td>\n",
       "      <td>너가좋아</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>좋아해</td>\n",
       "      <td>사랑해</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>사랑해</td>\n",
       "      <td>너가좋아</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>사랑해</td>\n",
       "      <td>좋아해</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>데이터마이닝</td>\n",
       "      <td>인공지능</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>데이터마이닝</td>\n",
       "      <td>김순태교수</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>인공지능</td>\n",
       "      <td>데이터마이닝</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>인공지능</td>\n",
       "      <td>김순태교수</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>김순태교수</td>\n",
       "      <td>데이터마이닝</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>김순태교수</td>\n",
       "      <td>인공지능</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>데이터</td>\n",
       "      <td>4차산업혁명</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>데이터</td>\n",
       "      <td>데이터마이닝</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4차산업혁명</td>\n",
       "      <td>데이터</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4차산업혁명</td>\n",
       "      <td>데이터마이닝</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>데이터마이닝</td>\n",
       "      <td>데이터</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>데이터마이닝</td>\n",
       "      <td>4차산업혁명</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>인공지능</td>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>인공지능</td>\n",
       "      <td>빅데이터</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>AI</td>\n",
       "      <td>인공지능</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재 벡터의 사이즈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(396, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 단어들에 매겨진 고유값\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'4차산업혁명': 18,\n 'AI': 2,\n '감독': 24,\n '게임': 28,\n '권상우': 23,\n '김사랑': 51,\n '김순태교수': 58,\n '남자친구': 11,\n '너가좋아': 40,\n '눈물연기': 56,\n '대학교': 26,\n '대학생': 5,\n '던전앤파이터': 50,\n '데이터': 25,\n '데이터마이닝': 21,\n '롤': 3,\n '롤챔스': 30,\n '리그오브레전드': 45,\n '리니지': 35,\n '메이플스토리': 39,\n '배우': 7,\n '보겸': 15,\n '블록체인': 22,\n '블리자드': 53,\n '빅데이터': 44,\n '사랑': 0,\n '사랑해': 14,\n '서든어택': 31,\n '스타크래프트': 41,\n '시공조아': 48,\n '심화영화': 43,\n '아프리카': 47,\n '여자친구': 55,\n '연구실': 13,\n '연기대상': 17,\n '영원한': 10,\n '영화': 49,\n '영화감독': 9,\n '영화관': 59,\n '영화배우': 42,\n '예뻐': 19,\n '오버워치': 8,\n '인공지능': 52,\n '임요환': 4,\n '전북대학교': 57,\n '전지현': 16,\n '정우성': 37,\n '조인성': 33,\n '좋아해': 34,\n '테란': 6,\n '페이커': 38,\n '폭풍저그': 46,\n '프로게이머': 36,\n '학교': 1,\n '행복': 32,\n '행복메이플스토리': 12,\n '행복해': 20,\n '홍진호': 27,\n '히어로즈오브스톰': 29,\n '히오스': 54}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "ONE_HOT_DIM = len(words)\n",
    "\n",
    "\n",
    "# 큰숫자 (예를들어 35, 43 등)를 원핫 인코딩 시키는 함수.\n",
    "# 35 -> (0,0,0,0,.....,1,0,0,0)\n",
    "# 36 -> (0,0,0,0,.....,0,1,0,0)\n",
    "def to_one_hot_encoding(data_point_index):\n",
    "    one_hot_encoding = np.zeros(ONE_HOT_DIM)\n",
    "    one_hot_encoding[data_point_index] = 1\n",
    "    return one_hot_encoding\n",
    "\n",
    "\n",
    "X = []  # 입력 배열입니다.\n",
    "Y = []  # 타겟단어입니다.\n",
    "\n",
    "for x, y in zip(df['input'], df['label']):\n",
    "    X.append(to_one_hot_encoding(word2int[x]))\n",
    "    Y.append(to_one_hot_encoding(word2int[y]))\n",
    "\n",
    "# 넘파이 어레이로 변경\n",
    "X_train = np.asarray(X)\n",
    "Y_train = np.asarray(Y)\n",
    "\n",
    "# 학습과정을 위한 placeholder 생성\n",
    "x = tf.placeholder(tf.float32, shape=(None, ONE_HOT_DIM))\n",
    "y_label = tf.placeholder(tf.float32, shape=(None, ONE_HOT_DIM))\n",
    "\n",
    "# 임베딩 차원 = 2\n",
    "EMBEDDING_DIM = 2\n",
    "\n",
    "# 이 두개의 값은 각각 히든레이어의 변수가 됩니다.\n",
    "W1 = tf.Variable(tf.random_normal([ONE_HOT_DIM, EMBEDDING_DIM]))\n",
    "b1 = tf.Variable(tf.random_normal([1])) \n",
    "hidden_layer = tf.add(tf.matmul(x, W1), b1)\n",
    "\n",
    "# 출력값\n",
    "W2 = tf.Variable(tf.random_normal([EMBEDDING_DIM, ONE_HOT_DIM]))\n",
    "b2 = tf.Variable(tf.random_normal([1]))\n",
    "prediction = tf.nn.softmax(tf.add(tf.matmul(hidden_layer, W2), b2))\n",
    "\n",
    "# 코스트합수 : 크로스 엔트로피\n",
    "loss = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(prediction), axis=[1]))\n",
    "\n",
    "# 학습과정\n",
    "train_op = tf.train.GradientDescentOptimizer(0.03).minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 0 현재 코스트 :  8.261164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 3000 현재 코스트 :  3.7754612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 6000 현재 코스트 :  3.2940671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 9000 현재 코스트 :  2.973565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 12000 현재 코스트 :  2.807256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 15000 현재 코스트 :  2.6847632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 18000 현재 코스트 :  2.607463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 21000 현재 코스트 :  2.562067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 24000 현재 코스트 :  2.5294802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 27000 현재 코스트 :  2.5020528\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "iteration = 30000\n",
    "for i in range(iteration):\n",
    "    sess.run(train_op, feed_dict={x: X_train, y_label: Y_train})\n",
    "    if i % 3000 == 0:\n",
    "        print('학습 '+str(i)+' 현재 코스트 : ', sess.run(loss, feed_dict={x: X_train, y_label: Y_train}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.6526104   0.21976887]\n [ 1.0076553  -2.2920887 ]\n [ 0.1660786  -2.1915896 ]\n [ 0.6893773   1.5020635 ]\n [-0.3311653   2.5610497 ]\n [ 0.57852435 -2.1122537 ]\n [-1.105024    2.1010907 ]\n [-3.2112558  -0.8140665 ]\n [ 1.204017    2.694388  ]\n [-2.00984     0.53412205]\n [ 2.2423663   0.24842922]\n [ 2.6371937  -0.04955615]\n [ 1.4328555   0.84131485]\n [ 0.37536994 -2.4422905 ]\n [ 3.0240202  -0.8032335 ]\n [-0.09732355  1.4532391 ]\n [-2.1855762  -0.7751728 ]\n [-2.2439198  -1.6307603 ]\n [ 1.9576694  -2.8473406 ]\n [ 2.578808   -0.7147277 ]\n [ 2.8815942  -0.26179272]\n [ 0.03481741 -2.4703236 ]\n [-0.13210075 -2.3498292 ]\n [-2.4359746  -0.88161457]\n [-1.9394548  -1.2802103 ]\n [ 0.19123672 -1.8667963 ]\n [ 0.5881223  -2.1268935 ]\n [ 0.0203377   2.9777083 ]\n [ 0.31575263  1.9988573 ]\n [ 1.1193954   1.8894702 ]\n [-0.8539281   3.4520493 ]\n [ 0.36964718  2.842315  ]\n [ 1.9847528   0.21730915]\n [-2.0025198  -0.12292494]\n [ 2.6156266  -0.83354414]\n [ 0.6441738   3.1958401 ]\n [ 1.4291228   1.6355855 ]\n [-2.738999    0.16771376]\n [-0.1934375   1.6888154 ]\n [ 0.41340065  1.7121168 ]\n [ 2.6096568  -0.8280668 ]\n [ 0.31315827  2.0444677 ]\n [-2.3542845   0.06021665]\n [-1.3434572  -0.16005985]\n [ 0.38861978 -2.216729  ]\n [ 2.0960298   1.7756802 ]\n [-2.0800107   3.1466427 ]\n [-0.025952    1.3763896 ]\n [ 1.1749688   1.6751004 ]\n [-1.9320908  -0.86767423]\n [ 1.1353046   2.0900245 ]\n [-2.3973722  -0.7182238 ]\n [ 0.42740178 -2.3242579 ]\n [ 0.6646096   2.3409078 ]\n [ 1.6848372   1.8458982 ]\n [ 2.309415    0.16239542]\n [-1.9581611  -1.4266118 ]\n [-0.0725133  -2.7683907 ]\n [ 0.9927512  -2.5483117 ]\n [-1.9769402   0.64841366]]\n"
     ]
    }
   ],
   "source": [
    "# 2차원의 히든레이어 벡터에 저장된 값\n",
    "vectors = sess.run(W1 + b1)\n",
    "print(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_df = pd.DataFrame(vectors, columns = ['x1', 'x2'])\n",
    "w2v_df['word'] = words\n",
    "w2v_df = w2v_df[['word', 'x1', 'x2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)\n",
    "# 한국어 폰트 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'w2v_df' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-47c801f937fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2v_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2v_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2v_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'w2v_df' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# matplotlib을 이용한 시각화\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for word, x1, x2 in zip(w2v_df['word'], w2v_df['x1'], w2v_df['x2']):\n",
    "    ax.annotate(word, (x1, x2))\n",
    "\n",
    "PADDING = 1.0\n",
    "x_axis_min = np.amin(vectors, axis=0)[0] - PADDING\n",
    "y_axis_min = np.amin(vectors, axis=0)[1] - PADDING\n",
    "x_axis_max = np.amax(vectors, axis=0)[0] + PADDING\n",
    "y_axis_max = np.amax(vectors, axis=0)[1] + PADDING\n",
    "\n",
    "plt.xlim(x_axis_min, x_axis_max)\n",
    "plt.ylim(y_axis_min, y_axis_max)\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 10)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://user-images.githubusercontent.com/38183241/48307056-3efed080-e588-11e8-94be-38dde658ccc0.png)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
